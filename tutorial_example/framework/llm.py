"""LLM interface and implementations"""
from abc import ABC, abstractmethod
from typing import List, Optional
import asyncio


class BaseLLM(ABC):
    """Base LLM interface"""
    
    @abstractmethod
    async def aask(self, prompt: str, system_msgs: Optional[List[str]] = None) -> str:
        """Async ask LLM"""
        pass


class MockLLM(BaseLLM):
    """Mock LLM for testing without API keys"""
    
    async def aask(self, prompt: str, system_msgs: Optional[List[str]] = None) -> str:
        # Simulate async delay
        await asyncio.sleep(0.1)
        
        # Return mock response based on prompt content
        prompt_lower = prompt.lower()
        
        # Check system message first to determine the role
        if system_msgs:
            sys_msg_lower = " ".join(system_msgs).lower()
            if "product manager" in sys_msg_lower or ("prd" in sys_msg_lower and "write" in sys_msg_lower):
                return """
# Product Requirement Document

## Product Overview
A simple application based on the requirement.

## User Stories
1. As a user, I want to use the application easily
2. As a user, I need the application to be reliable

## Functional Requirements
- Core functionality as specified
- User-friendly interface
- Error handling

## Non-functional Requirements
- Performance: Fast response times
- Reliability: 99% uptime
- Security: Data protection

## Success Metrics
- User satisfaction score > 4.5/5
- Performance targets met
- Zero critical bugs
"""
            elif "architect" in sys_msg_lower or ("design" in sys_msg_lower and "system" in sys_msg_lower):
                return """
# System Design Document

## Architecture Overview
The system follows a modular architecture with clear separation of concerns.

## System Architecture
- Frontend Layer: User interface components
- Business Logic Layer: Core application logic
- Data Layer: Data persistence and storage

## Components
1. Main Application Module
   - Entry point and orchestration
   - Error handling
   - Configuration management

2. Core Functionality Module
   - Business logic implementation
   - Data processing
   - Validation

3. Utility Module
   - Helper functions
   - Common utilities
   - Shared resources

## API Design
- RESTful API endpoints
- JSON request/response format
- Standard HTTP status codes
- Error handling and validation

## Technology Stack
- Programming Language: Python
- Framework: Standard library
- Testing: Unit tests
"""
            elif "engineer" in sys_msg_lower or ("code" in sys_msg_lower and "write" in sys_msg_lower):
                return """
# Main Application Code

def main():
    \"\"\"Main application entry point\"\"\"
    print("Application starting...")
    try:
        # Initialize application
        app = Application()
        app.run()
        return True
    except Exception as e:
        print(f"Error: {e}")
        return False

class Application:
    \"\"\"Main application class\"\"\"
    
    def __init__(self):
        self.initialized = False
    
    def run(self):
        \"\"\"Run the application\"\"\"
        self.initialized = True
        print("Application is running...")
        # Main application logic here

if __name__ == "__main__":
    main()
"""
        
        # Fallback to content-based detection
        if "requirement" in prompt_lower and "write" in prompt_lower and "prd" in prompt_lower:
            return """
# Main Application
def main():
    \"\"\"Main application entry point\"\"\"
    print("Hello, World!")
    print("Application is running...")
    return True

if __name__ == "__main__":
    main()
"""
        elif "design" in prompt_lower or "architecture" in prompt_lower:
            return """
# System Design

## Architecture
- Frontend: User interface
- Backend: Business logic
- Database: Data storage

## Components
1. Main module
2. Utility functions
3. Error handling

## API Design
- RESTful endpoints
- JSON responses
- Error codes
"""
        else:
            return f"Response to: {prompt[:100]}...\n\nThis is a mock response. In production, this would be generated by an LLM."


class OpenAILLM(BaseLLM):
    """OpenAI LLM implementation"""
    
    def __init__(self, model: str = "gpt-3.5-turbo", api_key: str = None):
        self.model = model
        try:
            import openai
            self.client = openai.AsyncOpenAI(api_key=api_key)
        except ImportError:
            raise ImportError("openai package is required. Install with: pip install openai")
    
    async def aask(self, prompt: str, system_msgs: Optional[List[str]] = None) -> str:
        messages = []
        
        if system_msgs:
            for sys_msg in system_msgs:
                messages.append({"role": "system", "content": sys_msg})
        
        messages.append({"role": "user", "content": prompt})
        
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages
        )
        
        return response.choices[0].message.content

